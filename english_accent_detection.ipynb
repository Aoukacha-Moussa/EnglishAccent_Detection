{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOag7AH6ZB1P"
      },
      "source": [
        "# libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5-Arf9umAGr",
        "outputId": "366d710e-6723-46d4-e52f-46d6eddbd3aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: whisper 1.1.10\n",
            "Uninstalling whisper-1.1.10:\n",
            "  Successfully uninstalled whisper-1.1.10\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from urllib.parse import urlparse\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "!pip uninstall -y whisper\n",
        "!pip install -q openai-whisper\n",
        "\n",
        "\n",
        "try:\n",
        "    import yt_dlp\n",
        "    from moviepy.editor import VideoFileClip\n",
        "    import imageio_ffmpeg\n",
        "    import whisper\n",
        "    import librosa\n",
        "except ImportError:\n",
        "    print(\"Installing required libraries...\")\n",
        "    !pip install -q yt-dlp moviepy imageio-ffmpeg openai-whisper librosa\n",
        "    import yt_dlp\n",
        "    from moviepy.editor import VideoFileClip\n",
        "    import imageio_ffmpeg\n",
        "    import whisper\n",
        "    import librosa\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    whisper.load_model\n",
        "except AttributeError:\n",
        "    print(\"Fixing whisper installation...\")\n",
        "    import sys\n",
        "    for mod in list(sys.modules.keys()):\n",
        "        if mod == 'whisper' or mod.startswith('whisper.'):\n",
        "            del sys.modules[mod]\n",
        "    !pip uninstall -y whisper\n",
        "    !pip install -q --force-reinstall openai-whisper\n",
        "    import whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4_vKXdHmR1Y"
      },
      "source": [
        "# class for video processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nT601tQ4masE"
      },
      "outputs": [],
      "source": [
        "class VideoProcessor:\n",
        "    def __init__(self):\n",
        "        self.supported_domains = [\n",
        "            'youtube.com', 'youtu.be', 'loom.com', 'vimeo.com',\n",
        "            'dropbox.com', 'drive.google.com'\n",
        "        ]\n",
        "        self.ydl_opts = {\n",
        "            'format': 'best[ext=mp4]/best',\n",
        "            'outtmpl': '%(title)s.%(ext)s',\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "        }\n",
        "\n",
        "    def validate_url(self, url: str) -> bool:\n",
        "        try:\n",
        "            parsed = urlparse(url)\n",
        "            if parsed.path.endswith(('.mp4', '.avi', '.mov', '.mkv', '.webm')):\n",
        "                return True\n",
        "            domain = parsed.netloc.lower()\n",
        "            return any(supported in domain for supported in self.supported_domains)\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    def download_video(self, url: str, output_dir: str) -> str:\n",
        "        try:\n",
        "            output_template = os.path.join(output_dir, '%(title)s.%(ext)s')\n",
        "            ydl_opts = {**self.ydl_opts, 'outtmpl': output_template}\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(url, download=False)\n",
        "                if info.get('duration', 0) > 600:\n",
        "                    raise Exception(\"Video too long (max 10 minutes supported)\")\n",
        "                ydl.download([url])\n",
        "                title = info.get('title', 'video')\n",
        "                ext = info.get('ext', 'mp4')\n",
        "                safe_title = re.sub(r'[<>:\"/\\\\|?*]', '_', title)\n",
        "                video_path = os.path.join(output_dir, f\"{safe_title}.{ext}\")\n",
        "                for file in os.listdir(output_dir):\n",
        "                    if file.endswith(('.mp4', '.webm', '.mkv', '.avi')):\n",
        "                        actual_path = os.path.join(output_dir, file)\n",
        "                        if actual_path != video_path:\n",
        "                            os.rename(actual_path, video_path)\n",
        "                        return video_path\n",
        "                return video_path\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to download video: {str(e)}\")\n",
        "\n",
        "    def extract_audio(self, video_path: str, output_dir: str) -> str:\n",
        "        try:\n",
        "            os.environ['IMAGEIO_FFMPEG_EXE'] = imageio_ffmpeg.get_ffmpeg_exe()\n",
        "\n",
        "            video_name = Path(video_path).stem\n",
        "            audio_path = os.path.join(output_dir, f\"{video_name}.wav\")\n",
        "\n",
        "            clip = VideoFileClip(video_path)\n",
        "            clip.audio.write_audiofile(audio_path, fps=16000, nbytes=2, codec='pcm_s16le',\n",
        "                                     ffmpeg_params=[\"-ac\", \"1\"], logger=None)\n",
        "            clip.close()\n",
        "\n",
        "            if not os.path.exists(audio_path) or os.path.getsize(audio_path) < 1000:\n",
        "                raise Exception(\"Audio extraction failed\")\n",
        "            return audio_path\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to extract audio: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1ZLEilnmb9P"
      },
      "source": [
        "# class for audio processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DTW3ftspmlMZ"
      },
      "outputs": [],
      "source": [
        "class AudioAnalyzer:\n",
        "    def __init__(self, model_size: str = \"base\"):\n",
        "        self.model_size = model_size\n",
        "        self.whisper_model = None\n",
        "\n",
        "    def load_whisper_model(self):\n",
        "        if self.whisper_model is None:\n",
        "            self.whisper_model = whisper.load_model(self.model_size)\n",
        "        return self.whisper_model\n",
        "\n",
        "    def transcribe_audio(self, audio_path: str):\n",
        "        try:\n",
        "            model = self.load_whisper_model()\n",
        "            result = model.transcribe(\n",
        "                audio_path,\n",
        "                language=\"en\",\n",
        "                task=\"transcribe\",\n",
        "                temperature=0.0\n",
        "            )\n",
        "            return {'text': result['text'].strip()}\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Transcription failed: {str(e)}\")\n",
        "\n",
        "    def get_speech_statistics(self, transcript: str, duration: float):\n",
        "        try:\n",
        "            words = transcript.split()\n",
        "            word_count = len(words)\n",
        "            wpm = (word_count / duration) * 60 if duration > 0 else 0\n",
        "            sentence_count = len(re.split(r'[.!?]+', transcript))\n",
        "\n",
        "            return {\n",
        "                'word_count': word_count,\n",
        "                'wpm': wpm,\n",
        "                'sentence_count': sentence_count\n",
        "            }\n",
        "        except Exception:\n",
        "            return {'word_count': 0, 'wpm': 0, 'sentence_count': 0}\n",
        "\n",
        "    def extract_acoustic_features(self, audio_path: str):\n",
        "        try:\n",
        "            y, sr = librosa.load(audio_path, sr=16000)\n",
        "            duration = len(y) / sr\n",
        "            return {'duration': duration}\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Feature extraction failed: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn46sEJfmmhd"
      },
      "source": [
        "# Accent detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uHCL9NH_m-fH"
      },
      "outputs": [],
      "source": [
        "class AccentDetector:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.word_patterns = {\n",
        "            \"American\": [\n",
        "                \"awesome\", \"guys\", \"totally\", \"math\", \"color\", \"elevator\", \"apartment\", \"vacation\",\n",
        "                \"sidewalk\", \"subway\", \"garbage\", \"mail\", \"truck\", \"dessert\", \"sneakers\", \"candy\",\n",
        "                \"movie\", \"cellphone\", \"garbage\", \"gas\", \"soccer\", \"fall\", \"parking lot\", \"line\",\n",
        "                \"drapes\", \"cookies\", \"closet\", \"pants\", \"gotten\", \"aluminum\", \"z\", \"tomato\",\n",
        "                \"schedule\", \"college\", \"spelled\", \"center\", \"defense\", \"meter\", \"catalog\", \"tire\"\n",
        "            ],\n",
        "            \"British\": [\n",
        "                \"brilliant\", \"proper\", \"cheers\", \"mate\", \"quid\", \"maths\", \"colour\", \"lift\", \"flat\",\n",
        "                \"holiday\", \"jumper\", \"nappy\", \"queue\", \"rubbish\", \"post\", \"lorry\", \"pudding\",\n",
        "                \"trainers\", \"sweets\", \"film\", \"mobile\", \"bin\", \"petrol\", \"football\", \"autumn\",\n",
        "                \"car park\", \"queue\", \"curtains\", \"biscuits\", \"wardrobe\", \"trousers\", \"got\",\n",
        "                \"aluminium\", \"zed\", \"tomahto\", \"schedule\", \"university\", \"spelt\", \"centre\",\n",
        "                \"defence\", \"metre\", \"catalogue\", \"tyre\"\n",
        "            ],\n",
        "            \"Australian\": [\n",
        "                \"mate\", \"reckon\", \"arvo\", \"barbie\", \"footy\", \"g'day\", \"ripper\", \"sheila\",\n",
        "                \"chockers\", \"thongs\", \"bottle-o\", \"servo\", \"ute\", \"Maccas\", \"brekkie\", \"bickie\",\n",
        "                \"mozzie\", \"daggy\", \"dunny\", \"esky\", \"stubby\", \"sunnies\", \"lollies\", \"manchester\",\n",
        "                \"docket\", \"capsicum\", \"rock melon\", \"fairy floss\", \"runners\", \"singlet\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "\n",
        "        self.phonetic_patterns = {\n",
        "            \"American\": [\n",
        "                r\"r\\b\", r\"t(?=\\w)\", r\"a(?=th)\", r\"(?<!\\w)a(?=\\s|$)\", r\"can't\\s+even\",\n",
        "                r\"(?<!\\w)o(?=\\w)\", r\"ot(?=\\w)\", r\"(?<!\\w)z\\w+\", r\"(?<!t)ed\\b\"\n",
        "            ],\n",
        "            \"British\": [\n",
        "                r\"r(?!\\w)\", r\"t\\b\", r\"a(?=ss|st|sk)\", r\"(?<!\\w)ah(?=\\s|$)\", r\"quite\", r\"rather\",\n",
        "                r\"indeed\", r\"(?<!\\w)o\\w+\", r\"(?<!\\w)ou\\w+\", r\"(?<!c)ent\\b\", r\"(?<!\\w)u(?=\\w)\",\n",
        "                r\"(?<!\\w)t\\w+\", r\"(?<!\\w)d\\w+\"\n",
        "            ],\n",
        "            \"Australian\": [\n",
        "                r\"ai(?=\\s|$)\", r\"ay(?=\\s|$)\", r\"i(?=\\s|$)\", r\"(?<!\\w)a\\w+\", r\"(?<!\\w)oi\\w+\",\n",
        "                r\"(?<!\\w)ei\\w+\", r\"(?<!\\w)ou\\w+\", r\"(?<!\\w)g'\", r\"(?<!\\w)strewth\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "\n",
        "        self.grammar_patterns = {\n",
        "            \"American\": [\n",
        "                r\"(?<!\\w)gotten\\b\", r\"(?<!\\w)I\\s+already\\s+\", r\"(?<!\\w)did\\s+you\\s+\",\n",
        "                r\"(?<!\\w)(?:he|she|it)\\s+(?:don't|doesn't)\\s+\"\n",
        "            ],\n",
        "            \"British\": [\n",
        "                r\"(?<!\\w)got\\b\", r\"(?<!\\w)I've\\s+already\\s+\", r\"(?<!\\w)have\\s+you\\s+\",\n",
        "                r\"(?<!\\w)(?:he|she|it)\\s+(?:have|has)n't\\s+\"\n",
        "            ],\n",
        "            \"Australian\": [\n",
        "                r\"(?<!\\w)reckon\\b\", r\"(?<!\\w)heaps\\s+of\\b\", r\"(?<!\\w)too\\s+easy\\b\",\n",
        "                r\"(?<!\\w)no\\s+worries\\b\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "\n",
        "        self.strong_indicators = {\n",
        "            \"American\": [\n",
        "                \"I could care less\", \"awesome sauce\", \"dude\", \"y'all\", \"right off the bat\",\n",
        "                \"touch base\", \"period\", \"for sure\", \"my bad\", \"rain check\"\n",
        "            ],\n",
        "            \"British\": [\n",
        "                \"bloody hell\", \"sorted\", \"fancy a\", \"spot on\", \"cheeky\", \"knackered\",\n",
        "                \"chuffed\", \"gobsmacked\", \"blimey\", \"bloke\", \"fortnight\", \"whilst\", \"proper\",\n",
        "                \"innit\", \"cheers\", \"rubbish\", \"brilliant\", \"quid\"\n",
        "            ],\n",
        "            \"Australian\": [\n",
        "                \"fair dinkum\", \"crikey\", \"no dramas\", \"yeah nah\", \"she'll be right\",\n",
        "                \"too easy\", \"flat out\", \"heaps good\", \"how ya going\", \"good on ya\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def analyze_word_usage(self, transcript):\n",
        "        scores = {}\n",
        "        transcript_lower = transcript.lower()\n",
        "        matches_by_accent = {}\n",
        "\n",
        "        for accent, words in self.word_patterns.items():\n",
        "            matches = []\n",
        "            for word in words:\n",
        "                if re.search(r'\\b' + re.escape(word) + r'\\b', transcript_lower):\n",
        "                    matches.append(word)\n",
        "\n",
        "\n",
        "            count = len(matches)\n",
        "\n",
        "\n",
        "            score = count / max(5, min(len(words), 15)) if count > 0 else 0\n",
        "\n",
        "            scores[accent] = score\n",
        "            matches_by_accent[accent] = matches\n",
        "\n",
        "        return scores, matches_by_accent\n",
        "\n",
        "    def analyze_phonetic_patterns(self, transcript):\n",
        "\n",
        "        scores = {}\n",
        "        transcript_lower = transcript.lower()\n",
        "        matches_by_accent = {}\n",
        "\n",
        "        for accent, patterns in self.phonetic_patterns.items():\n",
        "            matches = []\n",
        "            for pattern in patterns:\n",
        "                found = re.findall(pattern, transcript_lower)\n",
        "                if found:\n",
        "                    matches.extend(found[:5])\n",
        "\n",
        "\n",
        "            score = min(1.0, len(matches) / 10)\n",
        "            scores[accent] = score\n",
        "            matches_by_accent[accent] = matches\n",
        "\n",
        "        return scores, matches_by_accent\n",
        "\n",
        "    def analyze_grammar(self, transcript):\n",
        "\n",
        "        scores = {}\n",
        "        transcript_lower = transcript.lower()\n",
        "\n",
        "        for accent, patterns in self.grammar_patterns.items():\n",
        "            matches = []\n",
        "            for pattern in patterns:\n",
        "                found = re.findall(pattern, transcript_lower)\n",
        "                if found:\n",
        "                    matches.extend(found[:3])\n",
        "\n",
        "\n",
        "            score = min(1.0, len(matches) / 2)\n",
        "            scores[accent] = score\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def check_strong_indicators(self, transcript):\n",
        "\n",
        "        scores = {}\n",
        "        transcript_lower = transcript.lower()\n",
        "\n",
        "        for accent, phrases in self.strong_indicators.items():\n",
        "            matches = []\n",
        "            for phrase in phrases:\n",
        "                if phrase.lower() in transcript_lower:\n",
        "                    matches.append(phrase)\n",
        "\n",
        "\n",
        "            score = min(1.0, len(matches) * 0.8)\n",
        "            scores[accent] = score\n",
        "\n",
        "        return scores\n",
        "\n",
        "    def classify_accent(self, audio_path, transcript):\n",
        "\n",
        "        word_scores, word_matches = self.analyze_word_usage(transcript)\n",
        "        phonetic_scores, phonetic_matches = self.analyze_phonetic_patterns(transcript)\n",
        "        grammar_scores = self.analyze_grammar(transcript)\n",
        "        indicator_scores = self.check_strong_indicators(transcript)\n",
        "\n",
        "\n",
        "        analysis_details = {\n",
        "            \"word_scores\": word_scores,\n",
        "            \"phonetic_scores\": phonetic_scores,\n",
        "            \"grammar_scores\": grammar_scores,\n",
        "            \"indicator_scores\": indicator_scores,\n",
        "            \"word_matches\": word_matches,\n",
        "            \"phonetic_matches\": phonetic_matches\n",
        "        }\n",
        "\n",
        "        weights = {\n",
        "            \"word\": 0.4,\n",
        "            \"phonetic\": 0.3,\n",
        "            \"grammar\": 0.1,\n",
        "            \"indicator\": 0.2\n",
        "        }\n",
        "\n",
        "        combined_scores = {}\n",
        "        for accent in self.word_patterns.keys():\n",
        "            combined_scores[accent] = (\n",
        "                weights[\"word\"] * word_scores.get(accent, 0) +\n",
        "                weights[\"phonetic\"] * phonetic_scores.get(accent, 0) +\n",
        "                weights[\"grammar\"] * grammar_scores.get(accent, 0) +\n",
        "                weights[\"indicator\"] * indicator_scores.get(accent, 0)\n",
        "            )\n",
        "\n",
        "        british_words = [\"class\", \"bath\", \"dance\", \"half\", \"can't\", \"laugh\", \"tomato\", \"schedule\"]\n",
        "        british_word_pattern = r'\\b(' + '|'.join(british_words) + r')\\b'\n",
        "        british_words_in_transcript = re.findall(british_word_pattern, transcript.lower())\n",
        "\n",
        "        if british_words_in_transcript:\n",
        "            combined_scores[\"British\"] += 0.2 * min(1.0, len(british_words_in_transcript) / 3)\n",
        "\n",
        "\n",
        "        if all(score < 0.1 for score in combined_scores.values()):\n",
        "            top_accent = \"Neutral/Unknown\"\n",
        "            confidence = 30.0\n",
        "        else:\n",
        "            top_accent = max(combined_scores, key=combined_scores.get)\n",
        "\n",
        "\n",
        "            top_score = combined_scores[top_accent]\n",
        "\n",
        "\n",
        "            if top_score < 0.1:\n",
        "                confidence = 30.0\n",
        "            else:\n",
        "\n",
        "                confidence = min(100, 30 + (top_score * 70) ** 0.7 * 100)\n",
        "\n",
        "\n",
        "            other_scores = [s for a, s in combined_scores.items() if a != top_accent]\n",
        "            if other_scores:\n",
        "                next_best = max(other_scores)\n",
        "                separation = top_score - next_best\n",
        "\n",
        "\n",
        "                if separation > 0.1:\n",
        "                    confidence = min(100, confidence + 10)\n",
        "\n",
        "\n",
        "                if separation < 0.05 and top_score > 0:\n",
        "                    confidence = max(30, confidence - 10)\n",
        "\n",
        "\n",
        "            if top_score > 0.3:\n",
        "                confidence = max(confidence, 70)\n",
        "            if top_score > 0.5:\n",
        "                confidence = max(confidence, 85)\n",
        "\n",
        "\n",
        "        explanations = {\n",
        "            \"American\": \"Detected American accent based on vocabulary choices (like 'color', 'elevator'), pronunciation patterns, and sentence structure.\",\n",
        "            \"British\": \"Speech exhibits British English characteristics including vocabulary (like 'colour', 'lift'), non-rhotic pronunciation, and distinctive intonation patterns.\",\n",
        "            \"Australian\": \"Voice contains Australian English markers in word choice, rising intonation, and distinctive vowel sounds.\",\n",
        "            \"Neutral/Unknown\": \"No strong accent markers detected or insufficient speech sample.\"\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"accent\": top_accent,\n",
        "            \"confidence\": confidence,\n",
        "            \"explanation\": explanations.get(top_accent, \"Accent detected based on speech analysis.\"),\n",
        "            \"analysis_details\": analysis_details,\n",
        "            \"raw_scores\": combined_scores\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yF7kT60ZWaWS"
      },
      "outputs": [],
      "source": [
        "def analyze_video_accent(video_url):\n",
        "    processor = VideoProcessor()\n",
        "\n",
        "    if not processor.validate_url(video_url):\n",
        "        return {\"error\": \"Invalid or unsupported URL format\"}\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        try:\n",
        "            print(\"Downloading video...\")\n",
        "            video_path = processor.download_video(video_url, tmpdir)\n",
        "\n",
        "            print(\"Extracting audio...\")\n",
        "            audio_path = processor.extract_audio(video_path, tmpdir)\n",
        "\n",
        "            print(\"Transcribing speech...\")\n",
        "            analyzer = AudioAnalyzer()\n",
        "            transcript_result = analyzer.transcribe_audio(audio_path)\n",
        "\n",
        "            print(\"Extracting audio features...\")\n",
        "            features = analyzer.extract_acoustic_features(audio_path)\n",
        "\n",
        "            print(\"Analyzing speech statistics...\")\n",
        "            stats = analyzer.get_speech_statistics(\n",
        "                transcript_result['text'],\n",
        "                features['duration']\n",
        "            )\n",
        "\n",
        "            print(\"Detecting accent...\")\n",
        "            detector = AccentDetector()\n",
        "            accent_result = detector.classify_accent(\n",
        "                audio_path,\n",
        "                transcript_result['text']\n",
        "            )\n",
        "\n",
        "\n",
        "            result = {\n",
        "                \"accent_analysis\": accent_result,\n",
        "                \"transcript\": transcript_result['text'],\n",
        "                \"speech_stats\": stats\n",
        "            }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"error\": str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH0JZvScnLOB"
      },
      "source": [
        "# function to display results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EDrWvsF7gMCF"
      },
      "outputs": [],
      "source": [
        "def display_results(results):\n",
        "    if \"error\" in results:\n",
        "        print(f\"\\nError: {results['error']}\")\n",
        "    else:\n",
        "        accent = results[\"accent_analysis\"][\"accent\"]\n",
        "        confidence = results[\"accent_analysis\"][\"confidence\"]\n",
        "        explanation = results[\"accent_analysis\"][\"explanation\"]\n",
        "\n",
        "        print(\"\\n=== Accent Detection Result ===\")\n",
        "        print(f\"Accent: {accent}\")\n",
        "        print(f\"Confidence: {confidence:.2f}%\")\n",
        "        print(f\"Explanation: {explanation}\")\n",
        "\n",
        "        print(\"\\n=== Transcript ===\")\n",
        "        print(results[\"transcript\"])\n",
        "\n",
        "        print(\"\\n=== Speech Stats ===\")\n",
        "        print(f\"Words per Minute: {results['speech_stats']['wpm']:.2f}\")\n",
        "        print(f\"Word Count: {results['speech_stats']['word_count']}\")\n",
        "\n",
        "\n",
        "        if \"raw_scores\" in results[\"accent_analysis\"]:\n",
        "            print(\"\\n=== Raw Accent Scores ===\")\n",
        "            for accent, score in results[\"accent_analysis\"][\"raw_scores\"].items():\n",
        "                print(f\"  {accent}: {score:.4f}\")\n",
        "\n",
        "        if \"analysis_details\" in results[\"accent_analysis\"]:\n",
        "            print(\"\\n=== Accent Analysis Details ===\")\n",
        "            details = results[\"accent_analysis\"][\"analysis_details\"]\n",
        "\n",
        "            print(\"Word Scores:\")\n",
        "            for accent, score in details[\"word_scores\"].items():\n",
        "                print(f\"  {accent}: {score:.3f}\")\n",
        "\n",
        "            print(\"\\nPhonetic Scores:\")\n",
        "            for accent, score in details[\"phonetic_scores\"].items():\n",
        "                print(f\"  {accent}: {score:.3f}\")\n",
        "\n",
        "            print(\"\\nGrammar Scores:\")\n",
        "            for accent, score in details[\"grammar_scores\"].items():\n",
        "                print(f\"  {accent}: {score:.3f}\")\n",
        "\n",
        "            print(\"\\nStrong Indicator Scores:\")\n",
        "            for accent, score in details[\"indicator_scores\"].items():\n",
        "                print(f\"  {accent}: {score:.3f}\")\n",
        "\n",
        "            if details[\"word_matches\"]:\n",
        "                for accent, matches in details[\"word_matches\"].items():\n",
        "                    if matches:\n",
        "                        print(f\"\\n{accent} Word Matches:\", \", \".join(matches))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAjBhUFMnRjj",
        "outputId": "c575a3d6-417a-4867-8902-16a167a3f09b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading video...\n",
            "Extracting audio...\n",
            "Transcribing speech...\n",
            "Extracting audio features...\n",
            "Analyzing speech statistics...\n",
            "Detecting accent...\n",
            "\n",
            "=== Accent Detection Result ===\n",
            "Accent: American\n",
            "Confidence: 100.00%\n",
            "Explanation: Detected American accent based on vocabulary choices (like 'color', 'elevator'), pronunciation patterns, and sentence structure.\n",
            "\n",
            "=== Transcript ===\n",
            "Hey everyone, welcome to another Speak English with me video. In this video you will practice you're speaking with me. And as usual we will have a dialogue where one line will be mine and the next one will be yours. I'm going to say my line and then you will read your line out loud from the screen as if you were answering me and then vice versa. This is a very convenient and effective way to improve your speaking skills in English by yourself. Today's dialogue takes place in a movie theater. First we will listen to the full dialogue so that you know how to pronounce certain words and then we'll move to the practicing part. Okay, let's go. Hi, how are you doing? Welcome to AMC. Hi, how are you? Are you paying cash or card? Card. Are you a member? No, I'm not. Okay, what would you like to watch tonight? Two adults and one child for plus and boots please. Awesome. Could you choose your seats on the screen please? Sure. Wow, it's packed. Oh yeah, it usually gets pretty crowded in winter plus it's a federal holiday. Well, that makes sense. Not everyone likes the cold weather and winter outdoor activities. That's right. Okay, your total will be $28. All right, there you go. Thank you. It's theater number five to your right. Enjoy the movie. Thank you so much. Have a good one. Now let's practice. I will go first. Hi, how are you doing? Welcome to AMC. Are you paying cash or card? Are you a member? Okay, what would you like to watch tonight? Awesome. Could you choose your seats on the screen please? Oh yeah, it usually gets pretty crowded in winter plus it's a federal holiday. That's right. Okay, your total will be $28. Thank you. It's theater number five to your right. Enjoy the movie. Okay, amazing job everyone. Now we switch. You go first. Hi, how are you? Card. No, I'm not. Two adults and one child for Puss and Boots please. Sure, wow, it's packed. Well, that makes sense. Not everyone likes the cold weather and winter outdoor activities. All right, there you go. Thank you so much. Have a good one. Okay, guys, great job. I hope you enjoyed practicing your speaking skills with me and I hope this video was effective and beneficial for you. And if you haven't subscribed yet, please subscribe. Give this video a like and I'll see you in the next one.\n",
            "\n",
            "=== Speech Stats ===\n",
            "Words per Minute: 99.27\n",
            "Word Count: 423\n",
            "\n",
            "=== Raw Accent Scores ===\n",
            "  American: 0.4067\n",
            "  British: 0.3267\n",
            "  Australian: 0.3000\n",
            "\n",
            "=== Accent Analysis Details ===\n",
            "Word Scores:\n",
            "  American: 0.267\n",
            "  British: 0.067\n",
            "  Australian: 0.000\n",
            "\n",
            "Phonetic Scores:\n",
            "  American: 1.000\n",
            "  British: 1.000\n",
            "  Australian: 1.000\n",
            "\n",
            "Grammar Scores:\n",
            "  American: 0.000\n",
            "  British: 0.000\n",
            "  Australian: 0.000\n",
            "\n",
            "Strong Indicator Scores:\n",
            "  American: 0.000\n",
            "  British: 0.000\n",
            "  Australian: 0.000\n",
            "\n",
            "American Word Matches: awesome, guys, movie, line\n",
            "\n",
            "British Word Matches: holiday\n"
          ]
        }
      ],
      "source": [
        "video_url = \"https://www.youtube.com/watch?v=owlHiqL3nAI\"\n",
        "\n",
        "\n",
        "results = analyze_video_accent(video_url)\n",
        "display_results(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIEdxWBxnnpa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
